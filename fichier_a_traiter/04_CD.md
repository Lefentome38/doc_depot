# Le Déploiment Continu (CD)

## La livraison continue

La livraison continue est la suite logique de l’intégration continue. Dans l’intégration continue, nous cherchons à ce que le code compile bien, mais aussi qu’il soit fonctionnel en production et de qualité, en lançant le plus régulièrement possible les tests unitaires, ainsi que d’autres types de tests qui ne peuvent cependant pas être lancés sans avoir un environnement déployé. Le cycle continu et itératif de l'intégration et de la livraison continues.

Attention, la livraison continue ne doit pas être confondue avec le déploiement continu, qui est la suite logique de la livraison continue. Ces deux disciplines ont comme objectif de déployer une application en production. La différence se trouve dans l’automatisation du déploiement en production. La livraison continue s’arrête avant la production et la mise en production reste un acte manuel (que ce soit avec un outil ou automatisé via un clic de bouton, ou bien manuellement). La mise en production est soumise alors à la validation d’un être humain.
Le déploiement continu, quant à lui, est l’extension de la livraison continue : le déploiement se fait de manière automatisée par un pipeline. Toutes les étapes de compilation, tests unitaires et autres tests automatisés doivent alors être au vert avant de procéder au déploiement.

![Différence entre la livraison continue et le déploiement continu](https://user.oc-static.com/upload/2023/04/18/16818248792904_2C1-2.png)

Pour mettre en place la livraison continue, vous devez mettre en place quatre étapes :

1. La codification de l’infrastructure avec l’Infrastructure-as-Code.

2. Le déploiement et le test de votre application en environnement de test.

3. Le maintien en condition opérationnelle de votre application grâce au métier de Site Reliability Engineer.

4. La supervision de l’application et la mise en place de notifications d’alerte.

La livraison continue peut aussi se faire sur des environnements déjà configurés. L’étape d’Infrastructure-as-Code ne sera donc pas nécessaire. Cependant, l’Infrastructure-as-Code permet de créer des environnements éphémères qui seront créés et détruits à la demande et contenant exactement ce dont a besoin l’application pour fonctionner. Ces environnements n’étant pas démarrés tout le temps, cela permet de faire des économies d’argent. De plus, ces environnements étant créés automatiquement, cela conduit aussi à des économies de temps car les Ops ne perdent pas de temps à configurer ces environnements à chaque nouvelle livraison.

### Infrastructure-as-Code

L’Infrastructure-as-Code est une pratique qui consiste à décrire une infrastructure avec du code. Ce code est alors stocké avec le code de l’application et fait partie intégrante de cette dernière.

Les avantages sont nombreux :

- possibilité de créer des environnements à la demande
- création d’environnement en quelques minutes, contre plusieurs semaines dans une entreprise classique
- pilotage de l’infrastructure grâce au pipeline de livraison continue
- connaissance des logiciels installés sur la plateforme, grâce à l’outillage
- montée de version des environnements automatisés.

De manière générale, tous les outils qui respectent la norme [Open Container Initiative](https://opencontainers.org/) (OCI) peuvent piloter des conteneurs. Ces conteneurs deviennent alors l’artéfact de livraison standard et universel des applications.

Vous venez de voir à quel point l’Infrastructure-as-Code est pratique pour tester rapidement le changement de version d’un framework, ou le changement de version d’un middleware. En ne changeant que quelques lignes, nous pouvons alors relancer tout le pipeline, afin de voir s’il y a un impact sur le code applicatif.

`Les outils principaux de l’Infrastructure-as-Code sont Docker, Chef, Puppet, Ansible et Terraform`

### Le déploiement

L’étape la plus importante de la livraison continue est le déploiement du package que nous avons précédemment créé lors de l’intégration continue. Les avantages d’utiliser un outil pour automatiser le déploiement de l’application sont nombreux :

- cela permet à l’équipe de se concentrer sur le développement, là où elle a sa valeur à ajouter
- n’importe qui dans l’équipe peut déployer des logiciels
- les déploiements deviennent beaucoup moins sujets aux erreurs et beaucoup plus reproductibles
- déployer sur un nouvel environnement est facile
- les déploiements peuvent être très fréquents

`Pour pouvoir déployer les artéfacts précédemment créés, vous pourrez utiliser Spinnaker, Digital.ai Deploy ou UrbanCode`

Dans cette étape, nous ajoutons aussi d’autres types de tests, comme les tests de charge ou les tests de performance, autres que ceux lancés lors de l’intégration continue, plus pertinents et plus fonctionnels, afin de garantir que l’application fonctionne comme nous l’avons estimé.

L’avantage de tester à ce stade du pipeline est que l’application tourne sur un environnement de test presque identique à celui de la production. Pour des raisons de coût ou de non-nécessité de haute disponibilité, cet environnement est différent de la production dans son infrastructure. Il n’y aura pas autant de serveurs que la production, ni la même taille de machine en termes de CPU, RAM ou stockage, mais les versions de middleware ainsi que les configurations doivent être rigoureusement identiques. Son comportement sera donc le plus fidèle possible à celui qu’elle aura en production.

#### L'environnement de staging (ou de préproduction)

Le terme staging environment (en français : environnement de simulation) désigne un environnement serveur permettant de tester des sites web et des applications logicielles dans des conditions les plus proches possibles de la réalité.

Le but de déployer un environnement de staging est de valider les changements fait dans l’application dans un environnement isoproduction, c’est-à-dire qui réplique parfaitement les conditions de production des futurs changements. C’est pourquoi livrer une mise à jour fonctionnelle grâce à des conteneurs est parfait, car le conteneur devient de plus en plus l’artéfact de livraison universel.

Certains tests nécessitent aussi le déploiement de l’application avant d’être lancés, comme les tests de performance. Ces tests servent à prendre des décisions basées sur des métriques. Dans le cas du test de performance, nous pouvons imaginer un changement important dans l’interface de l’application qui a des impacts sur la performance générale de l’application. Avec ce genre de test, si les métriques récupérées sont trop dégradées, nous allons pouvoir prendre une décision manuelle avant de pousser l’application en production. Dans le cas d’une dégradation importante de la performance, il faudra alors ouvrir un nouveau bug de performance et refuser la livraison en production de l’application.

Grâce à nos pipelines de livraison continue et nos tests de performance lancés, nous allons alors pouvoir suivre l’évolution et la correction de ce bug avant qu’il n’atteigne des performances acceptables. Nous pourrons alors pousser ces changements manuellement en production grâce à notre chaîne DevOps.

Maintenant que l’environnement staging est déployé, il est possible de lancer des tests impossibles à lancer lors de la phase d’intégration continue.

#### Les tests avant déploiement

##### Les tests d’acceptance

Les tests d’acceptance sont des tests formels exécutés pour vérifier si un système satisfait à ses exigences opérationnelles. Ils exigent que l’application entière soit opérationnelle et se concentrent sur la réplication des comportements des utilisateurs. Mais ils peuvent aussi aller plus loin, en mesurant la performance du système, et rejeter les changements si certains objectifs ne sont pas atteints.

Ces tests peuvent être automatisés, mais aussi manuels, avec une équipe de test dédiée qui regardera si le logiciel correspond au besoin.

`Pour lancer des tests d’acceptance, vous pourrez utiliser Confluence, FitNesse ou Ranorex.`

##### Les tests de performance

Les tests de performance vérifient le comportement du système lorsqu’il est soumis à une charge importante. Ces tests ne sont pas fonctionnels et peuvent prendre différentes formes pour comprendre la fiabilité, la stabilité et la disponibilité de la plateforme. Par exemple, il peut s’agir d’observer les temps de réponse lors de l’exécution d’un grand nombre de requêtes, ou de voir comment le système se comporte avec une quantité importante de données.

Les tests de performance sont par nature assez coûteux à mettre en œuvre et à exécuter, mais ils peuvent vous aider à comprendre si de nouveaux changements vont dégrader votre système.

`Pour faire des tests de performance, vous pourrez utiliser JMeter, Apache Bench ou Gatling.`

##### Les smoke tests

Les smoke tests sont des tests de base qui vérifient les fonctionnalités de base de l’application. Ils sont conçus pour être rapides à exécuter et leur but est de vous donner l’assurance que les principales caractéristiques de votre système fonctionnent comme prévu. Ils peuvent être utiles juste après une nouvelle build, pour décider si vous pouvez ou non exécuter des tests plus coûteux, ou juste après un déploiement pour s’assurer que l’application fonctionne correctement dans le nouvel environnement déployé.

Par exemple, les smoke tests peuvent s’assurer que la base de données répond et est correctement configurée, mais aussi que les différents composants sont présents et envoient des données correctes, comme des API qui devraient répondre un code HTTP 200 ou une page web qui devrait s’afficher.

`Pour vous assurer du bon fonctionnement de l’application, vous pourrez utiliser Selenium, SoapUI ou Cypress.`

##### Les tests de sécurité

Les tests de sécurité sont des tests qui découvrent les vulnérabilités du système et déterminent que les données et les ressources du système sont protégées contre d’éventuels intrus. Ils garantissent que le système et l’application logicielle sont exempts de toute menace ou tout risque pouvant entraîner une perte. Le test de sécurité d’un système vise à trouver toutes les failles et faiblesses possibles du système qui pourraient entraîner la perte d’informations ou de réputation de l’organisation.

`Pour faire des tests de sécurité, vous pouvez utiliser Wapiti, Snyk ou ZAP (Zed Attack Proxy) d’OWASP`

Enfin, une fois l’environnement de staging déployé et testé, il ne reste plus qu’à déployer l’application sur l’environnement de production.

### Le monitoring et le métier de SRE

Le maintien en conditions opérationnelles des applications est une étape critique de notre pipeline DevOps. Cette étape garantit que l’application sera toujours accessible et disponible pour l’utilisateur final.

Afin de pouvoir superviser les applications et garantir que les serveurs sous-jacents continuent à avoir les ressources nécessaires au bon fonctionnement de l’application, il faut mettre en place des indicateurs surveillant les métriques du système comme le **CPU utilisé**, **la RAM disponible** ou encore **le stockage restant**.

Traditionnellement, cette étape était assurée par des exploitants qui s’assuraient que les indicateurs mis en place étaient bons, c’est-à-dire en vert sur les dashboards de production. Quand une des ressources monitorées devient non disponible, les indicateurs changent de couleur selon l’importance de l’indisponibilité : orange si la ressource est proche d’être épuisée, rouge si elle est épuisée. Si un de ces indicateurs n’était plus disponible, en devenant orange voire rouge (ce qui signifie une interruption de service), ces exploitants intervenaient alors manuellement sur la machine incriminée, redémarrant les processus qui ne fonctionnaient plus.

Avec la migration des applications dans le cloud, ou la transformation de ces applications en microservices, celles-ci sont devenues scalables et les environnements sont devenus dynamiques. Par conséquent, il est maintenant quasiment impossible de maîtriser tout un système d’information pour une personne seule.

À partir de ce constat, un nouveau métier est apparu : le Site Reliability Engineer (SRE), ou ingénieur de qualité opérationnelle en français. Le rôle du SRE est de s’assurer que l’application soit toujours disponible, de manière automatique, et qu’elle se répare toute seule. Le SRE se repose sur l’automatisation des infrastructures sous-jacentes de l’application, mais aussi sur de la supervision et de l’observabilité de ces applications que nous verrons plus en détail dans la suite de ce chapitre.

Pour cela, le SRE se base sur ce qu’on appelle les quatre signaux dorés que sont la latence, le trafic, les erreurs et la saturation. Ces quatre signaux dorés sont utilisés pour définir les Service Level Indicators (SLI). Ces SLI sont utilisés pour définir des Service Level Objectives(SLO). Enfin, ces SLO sont utilisés dans les Service Level Agreements (SLA).

Le monitoring, ou supervision, intervient une fois que notre application est déployée sur un environnement, que ce soit un environnement de staging, de test, de démonstration ou bien l’environnement de production lui-même.

Le principe est de récupérer certaines métriques qui ont du sens pour ceux qui interviennent sur l’application. Cela peut être par exemple le nombre de connexions HTTP, le nombre de requêtes à la base de données, le temps de réponse de certaines pages ; mais aussi des métriques davantage orientées métier, comme le chiffre d’affaires généré, ou le nombre de personnes inscrites sur l’application.

`Pour avoir un monitoring de vos applications, vous pourrez utiliser la suite Elastic, Prometheus ou Graylog.`

Les métriques peuvent aussi concerner la partie livraison en elle-même, ou le processus de développement. Par exemple, l’équipe peut mesurer le nombre de déploiements qu’elle effectue par jour, ainsi que deux autres indicateurs qui sont importants afin de mesurer la performance correction d’erreurs qui peuvent survenir en production : Mean-Time-Between-Failure et le Mean-Time-To-Recover.

#### Mean-Time-Between-Failure et Mean-Time-To-Recover

Le Mean-Time-Between-Failure (ou MTBF) est le temps moyen qui sépare deux erreurs en production. Plus ce temps est élevé, plus le système est stable et fiable, notamment du fait de la qualité des tests qui sont joués lors de la livraison continue.

Le Mean-Time-To-Recover (ou MTTR) est le temps moyen de correction entre deux erreurs de production. Plus ce temps est faible, plus l’équipe est apte à détecter des erreurs et à les corriger rapidement.

`Des outils comme Dynatrace, Sysdig ou New Relic permettent d’avoir ces métriques.`

Ces métriques comme le MTTR ou le MTBF sont indispensables mais ne sont pas suffisantes dans un contexte de déploiement microservices ou d’environnement scalable et dynamique comme le Cloud, c’est pourquoi une nouvelle discipline est apparue ces dernières années afin de pouvoir monitorer plus en détail et plus finement l’application dans ce contexte. Cette nouvelle discipline s’appelle l’observabilité et étend plus loin le concept de supervision que nous avons vu juste plus tôt dans le cours.

L’observabilité de l’application nous renvoie énormément de métriques afin d’avoir l’image la plus complète du comportement de l’application. Quand l’une de ces métriques est en échec, il est alors nécessaire d’avertir le plus rapidement l’équipe de support en notifiant celle-ci via des outils de notification. De plus, la première version d’une nouvelle fonctionnalité ou d’un nouveau produit ne couvre souvent pas entièrement les besoins des clients. Même lorsque l’équipe passe des semaines ou des mois à construire quelque chose, le produit final est souvent voué à manquer des fonctionnalités importantes. C’est le principe du Minimum Viable Product (MVP) en gestion Agile.

Il arrive donc très souvent de livrer des logiciels incomplets ou buggés, si l’équipe veut aller assez vite. Au lieu de vouloir éviter cela, il est nécessaire d’adopter l’idée de livrer des petites pièces de valeur.

En livrant plus vite, nous pouvons réparer les bugs tant que les livraisons restent petites et que nous savons ce qui a été modifié dans l’application. Quand les développements grossissent, ils deviennent plus difficiles à gérer et à remanier. Un feedback rapide, grâce aux tests en production et au monitoring, permet d’intervenir et de corriger le problème dès que possible. Il nous permet d’apprendre des clients, et des erreurs, au bon moment.

`Pour avoir un feedback rapide de vos déploiements, vous pourrez tout simplement utiliser Slack, Trello ou Twitter. `

#### Les notifications, aides au monitoring

La dernière étape du pipeline de livraison continue est l’étape de feedback rapide. Cette étape est celle qui va nous permettre de faire le lien entre la production (ops) et les développeurs (dev). C’est une étape qui donne de la visibilité aux développeurs sur des problèmes qu’il peut y avoir en production. Plus rapide est la détection des problèmes, plus rapide est leur correction.

## Sources

<https://fr.wikipedia.org/wiki/Cha%C3%AEne_d%27outils_Devops>

<https://openclassrooms.com/fr/courses/2035736-mettez-en-place-lintegration-et-la-livraison-continues-avec-la-demarche-devops>
