### Pourquoi l'Intégration Continue est Importante ?

L'intégration continue offre de nombreux avantages pour les équipes de développement de logiciels :

**Détection précoce des problèmes** : Les erreurs de code, les conflits et les problèmes de compatibilité sont détectés dès qu'un développeur fusionne son code. Cela permet de corriger ces problèmes rapidement, avant qu'ils ne deviennent plus complexes et coûteux à résoudre.

**Livraisons plus fréquentes** : Les pipelines CI automatisés permettent des déploiements plus fréquents, ce qui signifie que de nouvelles fonctionnalités ou corrections de bugs peuvent être livrées plus rapidement aux utilisateurs.

**Confiance dans le code** : En s'assurant que chaque morceau de code est testé, l'intégration continue renforce la confiance dans la qualité du logiciel.

**Collaboration facilitée** : Plusieurs développeurs peuvent travailler sur le même projet sans craindre de compromettre le code des autres.

**Historique des modifications** : Chaque changement apporté au code est enregistré et documenté, facilitant la compréhension des modifications précédentes.

### La compilation

La première étape de la CI/CD (celle qui paraît la plus évidente) est la compilation du code de manière continue. En effet, sans cette étape, le code est compilé manuellement sur le poste du développeur, afin que ce dernier s’assure que son code compile.

La mise en place d’une première étape de compilation dans un processus d’intégration continue permet de ne plus se soucier de modifications de code qui casseraient la compilation.

Le développeur doit s’assurer de bien envoyer son code source sur le dépôt central. En faisant cela, il déclenche une première étape de compilation, prenant en compte toutes les modifications dans son code source. Si la compilation est en erreur, le code est alors rejeté et le développeur doit corriger ses erreurs.

Après cette première étape, le code devient plus fiable, et le dépôt de code source garantit qu’à chaque instant, un développeur récupère un code qui compile. À cette étape, les tests ne sont pas encore exécutés. Le niveau de qualité du code peut donc être dégradé.

    Vous pourrez compiler votre code avec Maven, Ant, Gradle, MSBuild, NAnt, Gulp ou encore Grunt.

### Tester le code

Dans la deuxième étape, l’orchestrateur se charge de lancer les tests unitaires à la suite de la compilation. Ces tests unitaires (ou Unit Tests en anglais), généralement avec un framework associé, garantissent que le code respecte un certain niveau de qualité. Plus il y a de tests unitaires, plus le code est garanti sûr.

Les tests unitaires permettent de vérifier le bon fonctionnement d’une partie précise d’un logiciel ou d’une portion d’un programme. La multiplicité des tests unitaires oblige à les maintenir dans le temps, au fur et à mesure des évolutions du code.

### La qualité du code

Maintenant que les tests unitaires sont écrits et exécutés, nous commençons à avoir une meilleure qualité de code et à être rassurés sur la fiabilité et la robustesse de l’application. Grâce à la compilation et aux tests unitaires, nous pouvons maintenant mesurer la qualité du code. Tout ceci permet aux développeurs de maintenir dans le temps un code de très bonne qualité, alertant l’équipe en cas de dérive des bonnes pratiques de tests.

L’étape de qualité de code est différente de l’étape de test, car cette étape de qualité assure que le code sera maintenable et évolutif au fur et à mesure de son cycle de vie, alors que les tests servent à garantir que le code implémente bien les fonctionnalités demandées et ne contient pas (ou peu) de bugs.

Lors de l’étape de qualité de code, nous cherchons à assurer la plus petite dette technique possible de notre application. La dette technique est le temps nécessaire à la correction de bugs ou à l’ajout de nouvelles fonctionnalités lorsque nous ne respectons pas les règles de coding. La dette est exprimée en heures de correction. Plus cette dette est élevée, plus le code sera difficile à maintenir et à faire évoluer.

#### La sécurité du code

Dans l’approche DevSecOps, un autre type de tests joue un rôle important lors de la phase d’intégration continue : les tests de sécurité. La sécurité est devenue de plus en plus importante dans la création d’applications. Il est donc nécessaire de se prémunir d’attaques qui pourraient compromettre l’application en cours de développement. Ces tests de sécurité permettent de détecter au plus tôt les failles de sécurité dans les applications.

L’étape de qualité de code mesure aussi d’autres métriques, comme le nombre de vulnérabilités au sein du code, la couverture de test, mais aussi les code smells (qui sont des mauvaises pratiques à ne pas implémenter), la complexité cyclomatique (complexité du code applicatif) ou la duplication de code. C’est le rôle du développeur de respecter les normes définies et de corriger au fur et à mesure son code. Afin de renforcer la qualité du code et de ne pas autoriser le déploiement d’un code de mauvaise qualité, nous pouvons implémenter un arrêt complet du pipeline d’intégration continue si le code n’atteint pas la qualité requise.

### La création des livrables : le packaging et les artefacts

Le code, une fois compilé, doit être déployé dans un dépôt de livrables et versionné. Les binaires qui sont produits sont appelés artéfacts. Ces artéfacts doivent être accessibles à toutes les parties prenantes de l’application, afin de pouvoir les déployer et lancer les tests autres qu’unitaires (test de performance, test de bout en bout, etc.). Ces artéfacts sont disponibles dans un stockage, centralisé et organisé, de données. Ce peut être une ou plusieurs bases de données où les artéfacts sont localisés en vue de leur distribution sur le réseau, ou bien un endroit directement accessible aux utilisateurs.

## L'orchestration et mise en place un pipeline CI/CD

### Le Workflow

Le workflow de développement se déroule comme suit :

1. Le product owner travaille avec les utilisateurs finaux afin de définir un Product Backlog. Ce Product Backlog est constitué de différentes epics. Une epic est une description de haut niveau de ce que le client veut et, par conséquent, elle a une certaine valeur.

2. Ces epics doivent faire apparaître plusieurs critères, comme des wireframes ou autres écrans définissant l’application. Une epic en priorité haute migre en sprint backlog lorsque son périmètre est délimité avec un label Ready et le développement est confirmé avec le client. Ce n’est qu’à ce moment que l’epic est discutée avec l’équipe et décomposée en user stories, décrivant la feature à développer.

3. Les user stories doivent respecter la “Definition of Ready” définie plus tôt, lors du cycle de développement. Une user story n’est ready que si elle a bien été écrite et contient tous les éléments nécessaires à son développement durant le sprint.

4. Une fois que le sprint backlog a été décomposé en user stories, nous pouvons alors commencer la planification du sprint backlog.

### Compilation et test en continu

#### La stucture de votre dépôt git

Il existe deux grands modèle de structuration pour les dépôts git :

- Le modèle [_trunk-based development_](https://www.atlassian.com/fr/continuous-delivery/continuous-integration/trunk-based-development)

- Le modèle [gitflow](https://www.atlassian.com/fr/git/tutorials/comparing-workflows/gitflow-workflow), déjà abordé en cours précédemment

#### Le pipeline d'intégration continue

Un pipeline d'intégration continue est un ensemble d'automatisations et de processus qui permettent de fusionner en permanence le code des développeurs dans un référentiel commun, de le compiler, de l'exécuter et de tester automatiquement, puis de déployer la version mise à jour du logiciel si tous les tests passent avec succès. L'objectif principal est de détecter rapidement les conflits de code, les erreurs de compilation, les régressions et les problèmes de compatibilité.

Le pipeline va nous permettre d'automatiser toutes les étapes de compilation, de test, de vérification de la qualité du code et de packaging. Les phases de ce pipeline seront lancées successivement, lors de chaque nouveau push du code sur le repository.

Dans la plupart des outils de CI vous trouverez un langage commun :

- les _stages_ permettent de définir l’ordre des étapes, d'abord _build_ puis _tests_ en l'occurence.

- le _cache_ vous permettra de sauvegarder vos dépendances externe de votre projet entre vos différents _stages_

- Les _jobs_ sont les tâches à effectuer par votre CI. Il y aura autant de job à configurer que d'étape dans votre pipeline

- Enfin, _image_ sera le mot clé qui vous permettra de choisir l'image docker qui executera vos lignes de script

##### Les tests

Après la compilation, la phase de test s'exécute. L’objectif de cette étape est de s’assurer de lancer les tests écrits par les développeurs. Si un seul de ces tests échoue, le pipeline s’arrête.

Les tests doivent s’exécuter de la manière la plus rapide possible, afin d’avoir un feedback le plus rapide lui aussi. Pour arriver à ce niveau, il est nécessaire que les tests unitaires n’aient aucune dépendance vis-à-vis de systèmes externes, comme une base de données ou même le système de fichiers de la machine.

Les tests unitaires apportent trois atouts à la production :

- trouver les erreurs plus facilement. Les tests sont exécutés durant tout le développement, permettant de visualiser si le code fraîchement écrit correspond au besoin ;

- sécuriser la maintenance. Lors d’une modification d’un programme, les tests unitaires signalent les éventuelles régressions. En effet, certains tests peuvent échouer à la suite d’une modification, il faut donc soit réécrire le test pour le faire correspondre aux nouvelles attentes, soit corriger l’erreur se situant dans le code ;

- documenter le code. Les tests unitaires peuvent servir de complément à la documentation ; il est très utile de lire les tests pour comprendre comment s’utilise une méthode. De plus, il est possible que la documentation ne soit plus à jour, mais les tests, eux, correspondent à la réalité de l’application.

L’ensemble des tests unitaires doit être relancé après une modification du code, afin de vérifier qu’il n’y ait pas de régressions (l’apparition de nouveaux dysfonctionnements).

Si les tests échouent, le rôle du développeur est alors de :

- soit corriger le test qu’il a écrit, car la fonctionnalité a évolué et le test ne correspond plus ;

- soit faire évoluer le code, car le test a détecté un bug.

Il existe d’autres types de tests à lancer, qui dépendent des environnements où l’application est déployée, comme les tests de performance ou d’acceptation utilisateur en préproduction ; ou encore les smoke tests en production afin de garantir le fonctionnement normal de l’application en production.

##### Mesurez la qualité du code

Durant la phase de mesure de la qualité, il est également important de tester son code pour avoir une vision de la sécurité de ce dernier. Il existe trois types différents de tests de sécurité dans le code :

- le SAST(Static Application Security Testing) ou test de sécurité statique de l'application. Ce test consiste à tester le code source de l’application contre des vulnérabilités connues de l’application. Il n’est pas nécessaire d’avoir compilé l’application ;

- le DAST(Dynamic Application Security Testing) ou test de sécurité dynamique de l'application. Ce test consiste à tester dynamiquement une application déployée. Il intervient généralement durant la phase de déploiement continue de l’application, car ce test nécessite d’avoir une application déployée pour fonctionner. La fondation OWASP met à disposition des outils permettant de détecter des failles de sécurité dans des applications déployées. Ce type de test fonctionne en mode boite noire, c’est-à-dire que le test s’exécute sans avoir accès au code source, ni au binaire, mais directement par un point d’entrée de l’application comme une page web ou la page principale de l’application ;

- le IAST(Interactive Application Security Testing) ou test de sécurité interactif de l’application. Ce test consiste à tester l’application depuis l’intérieur de celle-ci. Contrairement au DAST, le IAST a accès au binaire de l’application et au code source. Il permet d’avoir une portée plus importante pour l’analyse des failles de sécurité de l’application.

Le SAST peut être lancé juste après la compilation du code, en même temps que les tests unitaires. Comme expliqué juste avant, le but est de tester le code source de l’application à la recherche de vulnérabilités connues du langage.

##### Packagez l'application avant de la déployer

L'interet du packaging est de faciliter de déployement de votre application en la plaçant dans un container.

L’une des pratiques clés du développement de logiciel moderne est d’isoler les applications déployées sur un même hôte ou sur un même cluster. Ceci permet d’éviter qu’elles interfèrent. Pour exécuter les applications, il est toutefois nécessaire d’exploiter des packages, des bibliothèques et divers composants logiciels. Pour exploiter ces ressources tout en isolant une application, on utilise depuis longtemps les **machines virtuelles**.

Celles-ci permettent de séparer les applications entre elles sur un même système, et de réduire les conflits entre les composants logiciels et la compétition pour les ressources. Cependant, une alternative a vu le jour : les **conteneurs**. Une machine virtuelle s’apparente à un système d’exploitation complet, d’une taille de plusieurs gigaoctets, permettant le partitionnement des ressources d’une infrastructure. Un conteneur délivre uniquement les ressources nécessaires à une application.

En effet, le conteneur partage le kernel de son OS avec d’autres conteneurs. C’est une différence avec une machine virtuelle, utilisant un hyperviseur pour distribuer les ressources hardware. Cette méthode permet de réduire l’empreinte des applications sur l’infrastructure. Le conteneur regroupe tous les composants système nécessaires à l’exécution du code, sans pour autant peser aussi lourd d’un OS complet. De même, un conteneur est plus léger et plus simple qu’une machine virtuelle et peut donc démarrer et s’arrêter plus rapidement. Il est donc plus réactif, et adaptable aux besoins fluctuants liés au ” scaling ” d’une application.

Dernier point fort : contrairement à un hyperviseur, un moteur de conteneur n’a pas besoin d’émuler un système d’exploitation complet. Le conteneur offre donc de meilleures performances qu’un déploiement sur machine virtuelle traditionnelle.

La dernière étape de vote CI sera donc d'avoir un job d'encapsulation de votre application compilé dans un container. Ce processus nous permettra, dans la livraison continue, de déployer facilement le même code sur différents environnements. Il sert aussi à figer le code compilé dans un package immuable. De ce fait, nous pouvons facilement redéployer le même code compilé sur n’importe quel autre environnement. Cela assure que le code ne soit pas modifié entre deux environnements et qu’un code testé soit déployé partout de la même façon

## Sources

<https://www.atlassian.com/fr/continuous-delivery/continuous-integration/trunk-based-development>

<https://www.atlassian.com/fr/git/tutorials/comparing-workflows/gitflow-workflow>
